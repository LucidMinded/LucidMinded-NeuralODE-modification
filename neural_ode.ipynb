{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.color_palette(\"bright\")\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "from torch.nn  import functional as F \n",
    "from torch.autograd import Variable\n",
    "\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode_solve(z0, t0, t1, f):\n",
    "    \"\"\"\n",
    "    Простейший метод эволюции ОДУ - метод Эйлера\n",
    "    \"\"\"\n",
    "    h_max = 0.05\n",
    "    n_steps = math.ceil((abs(t1 - t0) / h_max).max().item())\n",
    "\n",
    "    h = (t1 - t0) / n_steps\n",
    "    t = t0\n",
    "    z = z0\n",
    "\n",
    "    for i_step in range(n_steps):\n",
    "        z = z + h * f(z, t)\n",
    "        t = t + h\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEF(nn.Module):\n",
    "    def forward_with_grad(self, z, t, grad_outputs):\n",
    "        \"\"\"Compute f and a df/dz, a df/dp, a df/dt\"\"\"\n",
    "        batch_size = z.shape[0]\n",
    "\n",
    "        out = self.forward(z, t)\n",
    "\n",
    "        a = grad_outputs\n",
    "        adfdz, adfdt, *adfdp = torch.autograd.grad(\n",
    "            (out,),\n",
    "            (z, t) + tuple(self.parameters()),\n",
    "            grad_outputs=(a),\n",
    "            allow_unused=True,\n",
    "            retain_graph=True,\n",
    "        )\n",
    "        # метод grad автоматически суммирует градиенты для всех элементов батча, надо expand их обратно\n",
    "        if adfdp is not None:\n",
    "            adfdp = torch.cat([p_grad.flatten() for p_grad in adfdp]).unsqueeze(0)\n",
    "            adfdp = adfdp.expand(batch_size, -1) / batch_size\n",
    "        if adfdt is not None:\n",
    "            adfdt = adfdt.expand(batch_size, 1) / batch_size\n",
    "        return out, adfdz, adfdt, adfdp\n",
    "\n",
    "    def flatten_parameters(self):\n",
    "        p_shapes = []\n",
    "        flat_parameters = []\n",
    "        for p in self.parameters():\n",
    "            p_shapes.append(p.size())\n",
    "            flat_parameters.append(p.flatten())\n",
    "        return torch.cat(flat_parameters) if len(flat_parameters) > 0 else Tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ODEAdjoint(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, z0, t, flat_parameters, func):\n",
    "        assert isinstance(func, ODEF)\n",
    "        bs, *z_shape = z0.size()\n",
    "        time_len = t.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            z = torch.zeros(time_len, bs, *z_shape).to(z0)\n",
    "            z[0] = z0\n",
    "            for i_t in range(time_len - 1):\n",
    "                z0 = ode_solve(z0, t[i_t], t[i_t + 1], func)\n",
    "                z[i_t + 1] = z0\n",
    "\n",
    "        ctx.func = func\n",
    "        ctx.save_for_backward(t, z.clone(), flat_parameters)\n",
    "        return z\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, dLdz):\n",
    "        \"\"\"\n",
    "        dLdz shape: time_len, batch_size, *z_shape\n",
    "        \"\"\"\n",
    "        func = ctx.func\n",
    "        t, z, flat_parameters = ctx.saved_tensors\n",
    "        time_len, bs, *z_shape = z.size()\n",
    "        n_dim = np.prod(z_shape)\n",
    "        n_params = flat_parameters.size(0)\n",
    "\n",
    "        # Динамика аугментированной системы, которую надо эволюционировать обратно во времени\n",
    "        def augmented_dynamics(aug_z_i, t_i):\n",
    "            \"\"\"\n",
    "            Тензоры здесь - это срезы по времени\n",
    "            t_i - тензор с размерами: bs, 1\n",
    "            aug_z_i - тензор с размерами: bs, n_dim*2 + n_params + 1\n",
    "            \"\"\"\n",
    "            z_i, a = (\n",
    "                aug_z_i[:, :n_dim],\n",
    "                aug_z_i[:, n_dim : 2 * n_dim],\n",
    "            )  # игнорируем параметры и время\n",
    "\n",
    "            # Unflatten z and a\n",
    "            z_i = z_i.view(bs, *z_shape)\n",
    "            a = a.view(bs, *z_shape)\n",
    "            with torch.set_grad_enabled(True):\n",
    "                t_i = t_i.detach().requires_grad_(True)\n",
    "                z_i = z_i.detach().requires_grad_(True)\n",
    "                func_eval, adfdz, adfdt, adfdp = func.forward_with_grad(\n",
    "                    z_i, t_i, grad_outputs=a\n",
    "                )  # bs, *z_shape\n",
    "                adfdz = (\n",
    "                    adfdz.to(z_i)\n",
    "                    if adfdz is not None\n",
    "                    else torch.zeros(bs, *z_shape).to(z_i)\n",
    "                )\n",
    "                adfdp = (\n",
    "                    adfdp.to(z_i)\n",
    "                    if adfdp is not None\n",
    "                    else torch.zeros(bs, n_params).to(z_i)\n",
    "                )\n",
    "                adfdt = (\n",
    "                    adfdt.to(z_i) if adfdt is not None else torch.zeros(bs, 1).to(z_i)\n",
    "                )\n",
    "\n",
    "            # Flatten f and adfdz\n",
    "            func_eval = func_eval.view(bs, n_dim)\n",
    "            adfdz = adfdz.view(bs, n_dim)\n",
    "            return torch.cat((func_eval, -adfdz, -adfdp, -adfdt), dim=1)\n",
    "\n",
    "        dLdz = dLdz.view(time_len, bs, n_dim)  # flatten dLdz для удобства\n",
    "        with torch.no_grad():\n",
    "            ## Создадим плейсхолдеры для возвращаемых градиентов\n",
    "            # Распространенные назад сопряженные состояния, которые надо поправить градиентами от наблюдений\n",
    "            adj_z = torch.zeros(bs, n_dim).to(dLdz)\n",
    "            adj_p = torch.zeros(bs, n_params).to(dLdz)\n",
    "            # В отличие от z и p, нужно вернуть градиенты для всех моментов времени\n",
    "            adj_t = torch.zeros(time_len, bs, 1).to(dLdz)\n",
    "\n",
    "            for i_t in range(time_len - 1, 0, -1):\n",
    "                z_i = z[i_t]\n",
    "                t_i = t[i_t]\n",
    "                f_i = func(z_i, t_i).view(bs, n_dim)\n",
    "\n",
    "                # Рассчитаем прямые градиенты от наблюдений\n",
    "                dLdz_i = dLdz[i_t]\n",
    "                dLdt_i = torch.bmm(\n",
    "                    torch.transpose(dLdz_i.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1)\n",
    "                )[:, 0]\n",
    "\n",
    "                # Подправим ими сопряженные состояния\n",
    "                adj_z += dLdz_i\n",
    "                adj_t[i_t] = adj_t[i_t] - dLdt_i\n",
    "\n",
    "                # Упакуем аугментированные переменные в вектор\n",
    "                aug_z = torch.cat(\n",
    "                    (\n",
    "                        z_i.view(bs, n_dim),\n",
    "                        adj_z,\n",
    "                        torch.zeros(bs, n_params).to(z),\n",
    "                        adj_t[i_t],\n",
    "                    ),\n",
    "                    dim=-1,\n",
    "                )\n",
    "\n",
    "                # Решим (эволюционируем) аугментированную систему назад во времени\n",
    "                aug_ans = ode_solve(aug_z, t_i, t[i_t - 1], augmented_dynamics)\n",
    "\n",
    "                # Распакуем переменные обратно из решенной системы\n",
    "                adj_z[:] = aug_ans[:, n_dim : 2 * n_dim]\n",
    "                adj_p[:] += aug_ans[:, 2 * n_dim : 2 * n_dim + n_params]\n",
    "                adj_t[i_t - 1] = aug_ans[:, 2 * n_dim + n_params :]\n",
    "\n",
    "                del aug_z, aug_ans\n",
    "\n",
    "            ## Подправим сопряженное состояние в нулевой момент времени прямыми градиентами\n",
    "            # Вычислим прямые градиенты\n",
    "            dLdz_0 = dLdz[0]\n",
    "            dLdt_0 = torch.bmm(\n",
    "                torch.transpose(dLdz_0.unsqueeze(-1), 1, 2), f_i.unsqueeze(-1)\n",
    "            )[:, 0]\n",
    "\n",
    "            # Подправим\n",
    "            adj_z += dLdz_0\n",
    "            adj_t[0] = adj_t[0] - dLdt_0\n",
    "        return adj_z.view(bs, *z_shape), adj_t, adj_p, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralODE(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super(NeuralODE, self).__init__()\n",
    "        assert isinstance(func, ODEF)\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, z0, t=Tensor([0.0, 1.0]), return_whole_sequence=False):\n",
    "        t = t.to(z0)\n",
    "        z = ODEAdjoint.apply(z0, t, self.func.flatten_parameters(), self.func)\n",
    "        if return_whole_sequence:\n",
    "            return z\n",
    "        else:\n",
    "            return z[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_np(x):\n",
    "    return x.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trajectories(obs=None, times=None, trajs=None, save=None, figsize=(16, 8)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    if obs is not None:\n",
    "        if times is None:\n",
    "            times = [None] * len(obs)\n",
    "        for o, t in zip(obs, times):\n",
    "            o, t = to_np(o), to_np(t)\n",
    "            for b_i in range(o.shape[1]):\n",
    "                plt.scatter(o[:, b_i, 0], o[:, b_i, 1], c=t[:, b_i, 0], cmap=cm.plasma)\n",
    "\n",
    "    if trajs is not None:\n",
    "        for z in trajs:\n",
    "            z = to_np(z)\n",
    "            plt.plot(z[:, 0, 0], z[:, 0, 1], lw=1.5)\n",
    "        if save is not None:\n",
    "            plt.savefig(save)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conduct_experiment(ode_true, ode_trained, n_steps, name, plot_freq=10):\n",
    "    # Create data\n",
    "    z0 = Variable(torch.Tensor([[0.6, 0.3]]))\n",
    "\n",
    "    t_max = 6.29 * 5\n",
    "    n_points = 200\n",
    "\n",
    "    index_np = np.arange(0, n_points, 1, dtype=int)\n",
    "    index_np = np.hstack([index_np[:, None]])\n",
    "    times_np = np.linspace(0, t_max, num=n_points)\n",
    "    times_np = np.hstack([times_np[:, None]])\n",
    "\n",
    "    times = torch.from_numpy(times_np[:, :, None]).to(z0)\n",
    "    obs = ode_true(z0, times, return_whole_sequence=True).detach()\n",
    "    obs = obs + torch.randn_like(obs) * 0.01\n",
    "\n",
    "    # Get trajectory of random timespan\n",
    "    min_delta_time = 1.0\n",
    "    max_delta_time = 5.0\n",
    "    max_points_num = 32\n",
    "\n",
    "    def create_batch():\n",
    "        t0 = np.random.uniform(0, t_max - max_delta_time)\n",
    "        t1 = t0 + np.random.uniform(min_delta_time, max_delta_time)\n",
    "\n",
    "        idx = sorted(\n",
    "            np.random.permutation(index_np[(times_np > t0) & (times_np < t1)])[\n",
    "                :max_points_num\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        obs_ = obs[idx]\n",
    "        ts_ = times[idx]\n",
    "        return obs_, ts_\n",
    "\n",
    "    # Train Neural ODE\n",
    "    optimizer = torch.optim.Adam(ode_trained.parameters(), lr=0.01)\n",
    "    for i in range(n_steps):\n",
    "        obs_, ts_ = create_batch()\n",
    "\n",
    "        z_ = ode_trained(obs_[0], ts_, return_whole_sequence=True)\n",
    "        loss = F.mse_loss(z_, obs_.detach())\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % plot_freq == 0:\n",
    "            z_p = ode_trained(z0, times, return_whole_sequence=True)\n",
    "\n",
    "            plot_trajectories(\n",
    "                obs=[obs],\n",
    "                times=[times],\n",
    "                trajs=[z_p],\n",
    "                save=f\"assets/imgs/{name}/{i}.png\",\n",
    "            )\n",
    "            clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.01376676 -1.0261707 ]\n",
      " [ 0.97845036 -0.17162889]]\n"
     ]
    }
   ],
   "source": [
    "class LinearODEF(ODEF):\n",
    "    def __init__(self, W):\n",
    "        super(LinearODEF, self).__init__()\n",
    "        self.lin = nn.Linear(2, 2, bias=False)\n",
    "        self.lin.weight = nn.Parameter(W)\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        return self.lin(x)\n",
    "\n",
    "\n",
    "class SpiralFunctionExample(LinearODEF):\n",
    "    def __init__(self):\n",
    "        matrix = Tensor([[-0.1, -1.0], [1.0, -0.1]])\n",
    "        super(SpiralFunctionExample, self).__init__(matrix)\n",
    "\n",
    "\n",
    "class RandomLinearODEF(LinearODEF):\n",
    "    def __init__(self):\n",
    "        super(RandomLinearODEF, self).__init__(torch.randn(2, 2) / 2.0)\n",
    "\n",
    "\n",
    "ode_true = NeuralODE(SpiralFunctionExample())\n",
    "ode_trained = NeuralODE(RandomLinearODEF())\n",
    "\n",
    "conduct_experiment(ode_true, ode_trained, 2000, \"linear\", plot_freq=20)\n",
    "\n",
    "weights = to_np(ode_trained.func.lin.weight)\n",
    "print(weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
